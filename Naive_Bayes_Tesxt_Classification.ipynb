{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_Tesxt_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrestha-bikash/Naive-Bayes-Text-classification/blob/main/Naive_Bayes_Tesxt_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLAQWMeWB7zT",
        "outputId": "26bf1545-8df7-459c-cf0a-0cb93007d7d4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stpwords = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kOjQBoHkZh"
      },
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self, csv_file):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        print(self.df.head(10))\n",
        "        print(self.df.tail(10))\n",
        "\n",
        "        self.class_count = self.df['Class'].value_counts()\n",
        "        self.total_count = self.df['Class'].count()\n",
        "        print(self.class_count)\n",
        "\n",
        "    def cleaning_data(self, data):\n",
        "        # removing the punctuations from the sentences\n",
        "        remove_punc = [char for char in data if char not in string.punctuation]\n",
        "        remove_punc = ''.join(remove_punc)\n",
        "\n",
        "        # removing stopwords and returning the cleaned data\n",
        "        return [word.lower() for word in remove_punc.split() if word.lower() not in stpwords]\n",
        "    \n",
        "    def generate_keyword(self, data):\n",
        "        keywords = []\n",
        "        for item in data:\n",
        "            for word in item:\n",
        "                if word not in keywords:\n",
        "                    keywords.append(word)\n",
        "        return keywords\n",
        "    \n",
        "    def count_words(self, data, keywords):\n",
        "        # print(data)\n",
        "        count_arr = []\n",
        "\n",
        "        for word in keywords:\n",
        "            count = 0\n",
        "            for item in data:\n",
        "                if item == word:\n",
        "                    count += 1\n",
        "\n",
        "            count_arr.append(count)\n",
        "\n",
        "        return count_arr\n",
        "\n",
        "    def binary_count_words(self, data, keywords):\n",
        "        count_arr = [1 if word in data else 0 for word in keywords]\n",
        "        return count_arr\n",
        "\n",
        "    # calculate and store the conditional probability of each word\n",
        "    def calculate_cond_prob(self, word_count, total_word_count, total_keywords):\n",
        "        # applied laplace smoothing: adding 1 to the numerator as well as the size of the vocabulary(keywords) \n",
        "        # to the denominator to balance it.\n",
        "        return (word_count + 1)/(total_word_count + total_keywords)\n",
        "\n",
        "    def fit(self, is_binary):\n",
        "        doc = self.df['Document']\n",
        "        cleaned_doc = doc.apply(self.cleaning_data)\n",
        "\n",
        "        self.keywords = self.generate_keyword(cleaned_doc)\n",
        "        self.len_keywords = len(self.keywords)\n",
        "        print('keywords:', self.keywords)\n",
        "\n",
        "        # making a binary vectorize array for each row(i.e document) in the dataset\n",
        "        binary_vectorize_arr = cleaned_doc.apply(self.binary_count_words, args=[self.keywords])\n",
        "\n",
        "        # making a vectorize array for each row(i.e document) with the integer value count of it's keyword\n",
        "        integer_vectorize_arr = cleaned_doc.apply(self.count_words, args=[self.keywords])\n",
        "\n",
        "        if is_binary:\n",
        "            print('Binary vectorize word count:\\n', binary_vectorize_arr[:10])\n",
        "            vectorize_arr = binary_vectorize_arr\n",
        "        else:\n",
        "            print('Integer value vectorize word count:\\n', integer_vectorize_arr[:10])\n",
        "            vectorize_arr = integer_vectorize_arr\n",
        "\n",
        "        new_df = pd.DataFrame({'count_vector': vectorize_arr, 'class': self.df['Class']})\n",
        "\n",
        "        cs_only = new_df.loc[new_df['class'] == 'cs']\n",
        "        noncs_only = new_df.loc[new_df['class'] == 'non-cs']\n",
        "\n",
        "\n",
        "        # calculating the total word count of each word belonging to cs class, and storing as a vector\n",
        "        sum_count_cs = [sum(row[i] for row in cs_only['count_vector']) for i in range(self.len_keywords)]\n",
        "        # total number of words present in cs class\n",
        "        total_word_count_cs = sum(sum_count_cs)\n",
        "        print('total word counts for class cs:', total_word_count_cs)\n",
        "\n",
        "        # calculating the total word count of each word belonging to non-cs class, and storing as a vector\n",
        "        sum_count_noncs = [sum(row[i] for row in noncs_only['count_vector']) for i in range(self.len_keywords)]\n",
        "        # total number of words present in non-cs class\n",
        "        total_word_count_noncs = sum(sum_count_noncs)\n",
        "        print('total word count for class non-cs:', total_word_count_noncs)\n",
        "\n",
        "        # For class cs\n",
        "        self.cs_cond_prob = {}\n",
        "        # For class non-cs\n",
        "        self.noncs_cond_prob = {}\n",
        "\n",
        "        for index, item in enumerate(self.keywords):\n",
        "            # storing conditional probability of each keyword seperately based on the class\n",
        "            self.cs_cond_prob[item] = self.calculate_cond_prob(sum_count_cs[index], total_word_count_cs, self.len_keywords)\n",
        "            self.noncs_cond_prob[item] = self.calculate_cond_prob(sum_count_noncs[index], total_word_count_noncs, self.len_keywords)\n",
        "\n",
        "\n",
        "    def calculate_prior_prob(self, test_data, prob_dict):\n",
        "        prod_total = 1\n",
        "        for item in test_data:\n",
        "            if item in self.keywords:\n",
        "                item_prob = prob_dict[item]\n",
        "            else:\n",
        "                # if the keyword from the test dataset does not present in the keywords set, give it a small probability\n",
        "                item_prob = 0.0001\n",
        "            prod_total = prod_total * item_prob\n",
        "        \n",
        "        return prod_total\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        self.test_data = test_df['Document']\n",
        "        self.test_label = test_df['Class']\n",
        "        # calculating the class probability\n",
        "        class_prob = {}\n",
        "        class_prob['cs'] = self.class_count['cs']/self.total_count\n",
        "        class_prob['noncs'] = self.class_count['non-cs']/self.total_count\n",
        "\n",
        "        # store predictions\n",
        "        self.prediction = []\n",
        "\n",
        "        print('\\n\\n *** Prediction *** \\n')\n",
        "        for test in self.test_data:\n",
        "            test_cleaned = self.cleaning_data(test)\n",
        "\n",
        "            # calculating the posterior probabilities\n",
        "            test_cs_prob = class_prob['cs'] * self.calculate_prior_prob(test_cleaned, self.cs_cond_prob)\n",
        "            test_noncs_prob = class_prob['noncs'] * self.calculate_prior_prob(test_cleaned, self.noncs_cond_prob)\n",
        "\n",
        "            if test_cs_prob > test_noncs_prob:\n",
        "                self.prediction.append('cs')\n",
        "            else:\n",
        "                self.prediction.append('non-cs')\n",
        "        \n",
        "        for i in range(len(self.prediction)):\n",
        "            print('Predicted class:', self.prediction[i], ', Actual Class:', self.test_label[i])\n",
        "\n",
        "    \n",
        "    def calculate_accuracy(self):\n",
        "        self.accuracy = int(np.count_nonzero(self.prediction == self.test_label))\n",
        "        print(\"Accuracy: %3.2f%%\"%((self.accuracy/len(self.test_label))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIs68u1tMRdm"
      },
      "source": [
        "## Preview of Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niQjnVhQNhuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78409d67-347f-4f79-a84f-6955594bcabc"
      },
      "source": [
        "NB = NaiveBayes('Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Id                                           Document Class\n",
            "0   1  Search a sorted array by repeatedly dividing t...    cs\n",
            "1   2  data structure is a particular way of organizi...    cs\n",
            "2   3  linked list is represented by a pointer to the...    cs\n",
            "3   4  The left and right subtree each must also be a...    cs\n",
            "4   5  Machine Learning is the field of study that gi...    cs\n",
            "5   6  Linear Regression is a machine learning algori...    cs\n",
            "6   7  Regression models a target prediction value ba...    cs\n",
            "7   8  Like arrays, Linked List is a linear data stru...    cs\n",
            "8   9  Extra memory space for a pointer is required w...    cs\n",
            "9  10  Gradient Descent is an optimization algorithm ...    cs\n",
            "    Id                                           Document   Class\n",
            "25  26  If you are unable to make it to a safe shelter...  non-cs\n",
            "26  27  business administration covers the breadth of ...  non-cs\n",
            "27  28  Pranayama arouses the internal energy of a per...  non-cs\n",
            "28  29  TORNADO WARNING means that a tornado has been ...  non-cs\n",
            "29  30  Commerce Bank offers personal and business ban...  non-cs\n",
            "30  31  commerce refers to the exchange of goods, serv...  non-cs\n",
            "31  32  Having health insurance coverage can save you ...  non-cs\n",
            "32  33  Architecture is the art and science of designi...  non-cs\n",
            "33  34  Scientific evidence demonstrates that wearing ...  non-cs\n",
            "34  35  Sport performance is a complex mixture of biom...  non-cs\n",
            "cs        20\n",
            "non-cs    15\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx6ByKahMbKz"
      },
      "source": [
        "## Preview of Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "zWaLwLntGVCV",
        "outputId": "a61167b1-17d6-4751-af9e-a39ab3e4b416"
      },
      "source": [
        "test_doc = ['Artificial intelligence is emerging rapidly in the field of science',\n",
        "        'Management of products using computer is important in business',\n",
        "        'Dealing with passwords is about as pleasant as cleaning gutters or filing taxes',\n",
        "        'Understand the structure of singly linked list and doubly linked list',\n",
        "        'A handful of companies are working to turn household trash into low-emissions fuels for planes, trains and trucks',\n",
        "        'Technology stocks surged, helping the Nasdaq Composite rebound a day after sliding into correction territory',\n",
        "        'Binary Naive Bayes classifiers for detecting spam emails']\n",
        "test_class = ['cs', 'non-cs', 'non-cs', 'cs', 'non-cs', 'non-cs', 'cs']\n",
        "\n",
        "test_df = pd.DataFrame({'Document': test_doc, 'Class': test_class})\n",
        "\n",
        "test_df.head(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Artificial intelligence is emerging rapidly in...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Management of products using computer is impor...</td>\n",
              "      <td>non-cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dealing with passwords is about as pleasant as...</td>\n",
              "      <td>non-cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Understand the structure of singly linked list...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A handful of companies are working to turn hou...</td>\n",
              "      <td>non-cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Technology stocks surged, helping the Nasdaq C...</td>\n",
              "      <td>non-cs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Binary Naive Bayes classifiers for detecting s...</td>\n",
              "      <td>cs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Document   Class\n",
              "0  Artificial intelligence is emerging rapidly in...      cs\n",
              "1  Management of products using computer is impor...  non-cs\n",
              "2  Dealing with passwords is about as pleasant as...  non-cs\n",
              "3  Understand the structure of singly linked list...      cs\n",
              "4  A handful of companies are working to turn hou...  non-cs\n",
              "5  Technology stocks surged, helping the Nasdaq C...  non-cs\n",
              "6  Binary Naive Bayes classifiers for detecting s...      cs"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAPj1MSyMfQV"
      },
      "source": [
        "## Case I with Binary value count vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lne_cfKgWsHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506c9d19-8fac-4448-ee51-6d879f16efdc"
      },
      "source": [
        "# For case I\n",
        "NB.fit(is_binary=True)\n",
        "NB.predict(test_df)\n",
        "\n",
        "print('\\nTest set Accuracy')\n",
        "NB.calculate_accuracy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords: ['search', 'sorted', 'array', 'repeatedly', 'dividing', 'interval', 'half', 'data', 'structure', 'particular', 'way', 'organizing', 'computer', 'used', 'effectively', 'linked', 'list', 'represented', 'pointer', 'first', 'node', 'left', 'right', 'subtree', 'must', 'also', 'binary', 'tree', 'machine', 'learning', 'field', 'study', 'gives', 'computers', 'capability', 'learn', 'without', 'explicitly', 'programmed', 'linear', 'regression', 'algorithm', 'based', 'supervised', 'models', 'target', 'prediction', 'value', 'independent', 'variables', 'like', 'arrays', 'extra', 'memory', 'space', 'required', 'element', 'gradient', 'descent', 'optimization', 'minimizing', 'cost', 'function', 'various', 'algorithms', 'make', 'intelligent', 'act', 'intelligently', 'students', 'get', 'confused', 'artificial', 'intelligence', 'actual', 'mining', 'task', 'semiautomatic', 'automatic', 'analysis', 'large', 'quantities', 'clustering', 'discovering', 'groups', 'structures', 'classification', 'generalizing', 'known', 'apply', 'new', 'decision', 'powerful', 'popular', 'tool', 'naive', 'bayes', 'classifiers', 'collection', 'bayes’', 'theorem', 'deep', 'part', 'broader', 'family', 'methods', 'neural', 'networks', 'vision', 'interdisciplinary', 'scientific', 'deals', 'gain', 'highlevel', 'understanding', 'digital', 'images', 'videos', 'natural', 'language', 'processing', 'nlp', 'concerned', 'interactions', 'human', 'account', 'management', 'postsales', 'role', 'focuses', 'nurturing', 'client', 'relationships', 'little', 'spoon', 'delivers', 'fresh', 'organic', 'baby', 'food', 'thats', 'personalized', 'babys', 'nutritional', 'needs', 'aarmy', 'subscription', 'unlimited', 'access', 'hundreds', 'workouts', 'sustainable', 'home', 'essentials', 'delivered', 'doorstep', 'grove', 'collaborative', 'ecofriendly', 'household', 'cleaning', 'products', 'average', 'savings', '2500', 'compared', 'lenders', 'fees', 'closing', 'costs', 'unable', 'safe', 'shelter', 'car', 'cover', 'head', 'abandon', 'seek', 'business', 'administration', 'covers', 'breadth', 'businessrelated', 'disciplines', 'defined', 'core', 'curriculum', 'pranayama', 'arouses', 'internal', 'energy', 'person', 'makes', 'healthy', 'balanced', 'active', 'tornado', 'warning', 'means', 'sighted', 'indicated', 'weather', 'radar', 'commerce', 'bank', 'offers', 'personal', 'banking', 'checking', 'mortgages', 'loans', 'investing', 'credit', 'cards', 'refers', 'exchange', 'goods', 'services', 'something', 'businesses', 'entities', 'health', 'insurance', 'coverage', 'save', 'money', 'doctors', 'visits', 'prescriptions', 'drugs', 'preventative', 'care', 'architecture', 'art', 'science', 'designing', 'buildings', 'andnonbuilding', 'evidence', 'demonstrates', 'wearing', 'face', 'masks', 'implementing', 'lockdowns', 'reduce', 'spread', 'covid19', 'sport', 'performance', 'complex', 'mixture', 'biomechanical', 'emotional', 'factors', 'training', 'techniques']\n",
            "Binary vectorize word count:\n",
            " 0    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "1    [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "3    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "7    [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...\n",
            "8    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "9    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
            "Name: Document, dtype: object\n",
            "total word counts for class cs: 164\n",
            "total word count for class non-cs: 141\n",
            "\n",
            "\n",
            " *** Prediction *** \n",
            "\n",
            "Predicted class: cs , Actual Class: cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: cs\n",
            "\n",
            "Test set Accuracy\n",
            "Accuracy: 85.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02y7VYngNBzo"
      },
      "source": [
        "## Case II with Integer value count vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwdVm3n5T0PJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca4197d1-6417-4a39-c56c-94542432a18e"
      },
      "source": [
        "# For case II\n",
        "NB.fit(is_binary=False)\n",
        "NB.predict(test_df)\n",
        "\n",
        "print('\\nTest set Accuracy')\n",
        "NB.calculate_accuracy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords: ['search', 'sorted', 'array', 'repeatedly', 'dividing', 'interval', 'half', 'data', 'structure', 'particular', 'way', 'organizing', 'computer', 'used', 'effectively', 'linked', 'list', 'represented', 'pointer', 'first', 'node', 'left', 'right', 'subtree', 'must', 'also', 'binary', 'tree', 'machine', 'learning', 'field', 'study', 'gives', 'computers', 'capability', 'learn', 'without', 'explicitly', 'programmed', 'linear', 'regression', 'algorithm', 'based', 'supervised', 'models', 'target', 'prediction', 'value', 'independent', 'variables', 'like', 'arrays', 'extra', 'memory', 'space', 'required', 'element', 'gradient', 'descent', 'optimization', 'minimizing', 'cost', 'function', 'various', 'algorithms', 'make', 'intelligent', 'act', 'intelligently', 'students', 'get', 'confused', 'artificial', 'intelligence', 'actual', 'mining', 'task', 'semiautomatic', 'automatic', 'analysis', 'large', 'quantities', 'clustering', 'discovering', 'groups', 'structures', 'classification', 'generalizing', 'known', 'apply', 'new', 'decision', 'powerful', 'popular', 'tool', 'naive', 'bayes', 'classifiers', 'collection', 'bayes’', 'theorem', 'deep', 'part', 'broader', 'family', 'methods', 'neural', 'networks', 'vision', 'interdisciplinary', 'scientific', 'deals', 'gain', 'highlevel', 'understanding', 'digital', 'images', 'videos', 'natural', 'language', 'processing', 'nlp', 'concerned', 'interactions', 'human', 'account', 'management', 'postsales', 'role', 'focuses', 'nurturing', 'client', 'relationships', 'little', 'spoon', 'delivers', 'fresh', 'organic', 'baby', 'food', 'thats', 'personalized', 'babys', 'nutritional', 'needs', 'aarmy', 'subscription', 'unlimited', 'access', 'hundreds', 'workouts', 'sustainable', 'home', 'essentials', 'delivered', 'doorstep', 'grove', 'collaborative', 'ecofriendly', 'household', 'cleaning', 'products', 'average', 'savings', '2500', 'compared', 'lenders', 'fees', 'closing', 'costs', 'unable', 'safe', 'shelter', 'car', 'cover', 'head', 'abandon', 'seek', 'business', 'administration', 'covers', 'breadth', 'businessrelated', 'disciplines', 'defined', 'core', 'curriculum', 'pranayama', 'arouses', 'internal', 'energy', 'person', 'makes', 'healthy', 'balanced', 'active', 'tornado', 'warning', 'means', 'sighted', 'indicated', 'weather', 'radar', 'commerce', 'bank', 'offers', 'personal', 'banking', 'checking', 'mortgages', 'loans', 'investing', 'credit', 'cards', 'refers', 'exchange', 'goods', 'services', 'something', 'businesses', 'entities', 'health', 'insurance', 'coverage', 'save', 'money', 'doctors', 'visits', 'prescriptions', 'drugs', 'preventative', 'care', 'architecture', 'art', 'science', 'designing', 'buildings', 'andnonbuilding', 'evidence', 'demonstrates', 'wearing', 'face', 'masks', 'implementing', 'lockdowns', 'reduce', 'spread', 'covid19', 'sport', 'performance', 'complex', 'mixture', 'biomechanical', 'emotional', 'factors', 'training', 'techniques']\n",
            "Integer value vectorize word count:\n",
            " 0    [2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "1    [0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "3    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "5    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "6    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "7    [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...\n",
            "8    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "9    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
            "Name: Document, dtype: object\n",
            "total word counts for class cs: 172\n",
            "total word count for class non-cs: 145\n",
            "\n",
            "\n",
            " *** Prediction *** \n",
            "\n",
            "Predicted class: cs , Actual Class: cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: cs\n",
            "Predicted class: non-cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: non-cs\n",
            "Predicted class: cs , Actual Class: cs\n",
            "\n",
            "Test set Accuracy\n",
            "Accuracy: 85.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cJeVHPy_SnJ"
      },
      "source": [
        "### There is an accuracy of 85.71% because our algorithm classifies one document incorrectly. The sixth document in our test set belongs to \"non-cs\" class but the algorithm classifies it as a \"cs\" class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbrqGwvAEO_G",
        "outputId": "10065a16-e30c-48cf-f13d-2cda52bf0a7a"
      },
      "source": [
        "! jupyter nbconvert --to html Project3_Naive_Bayes.ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook Project3_Naive_Bayes.ipynb to html\n",
            "[NbConvertApp] Writing 323308 bytes to Project3_Naive_Bayes.html\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}